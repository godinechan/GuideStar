{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Vendor-Classifier\" data-toc-modified-id=\"Vendor-Classifier-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Vendor Classifier</a></span><ul class=\"toc-item\"><li><span><a href=\"#VC-functions-and-packages\" data-toc-modified-id=\"VC-functions-and-packages-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>VC functions and packages</a></span></li><li><span><a href=\"#VC-Variables-declaration\" data-toc-modified-id=\"VC-Variables-declaration-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>VC Variables declaration</a></span></li><li><span><a href=\"#VC-Main\" data-toc-modified-id=\"VC-Main-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>VC Main</a></span></li></ul></li><li><span><a href=\"#Cosine-Similarity-for-Company-Names\" data-toc-modified-id=\"Cosine-Similarity-for-Company-Names-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Cosine Similarity for Company Names</a></span><ul class=\"toc-item\"><li><span><a href=\"#CS-functions-and-packages\" data-toc-modified-id=\"CS-functions-and-packages-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>CS functions and packages</a></span></li><li><span><a href=\"#CS-Variable-Declaration\" data-toc-modified-id=\"CS-Variable-Declaration-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>CS Variable Declaration</a></span></li><li><span><a href=\"#CS-Main\" data-toc-modified-id=\"CS-Main-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>CS Main</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vendor Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VC functions and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This is the vendor classifier that classifies companies with different\n",
    "service categories according to their service types\"\"\"\n",
    "\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from autocorrect import spell\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn import linear_model\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    Function for reading input file\n",
    "    input:\n",
    "        filename (string): name of the file\n",
    "    output:\n",
    "        df (dataframe): input dataframe\n",
    "\"\"\"\n",
    "#read input file\n",
    "def read_txt(filename):\n",
    "    if filename.split('.')[1] == 'csv':\n",
    "        df = pd.read_csv(r'vc_input_train.csv')\n",
    "        return df\n",
    "    elif filename.split('.')[1] == 'txt':\n",
    "        with open(\"vc_input_train.txt\", encoding='utf-16') as f:\n",
    "            contents = f.read()\n",
    "        if sys.version_info[0] < 3: \n",
    "            from StringIO import StringIO\n",
    "        else:\n",
    "            from io import StringIO\n",
    "        TESTDATA=StringIO(contents)\n",
    "        df = pd.read_csv(TESTDATA, sep=\"|\", error_bad_lines=False)\n",
    "        return df\n",
    "    else:\n",
    "        print(\"file type non recognized\")\n",
    "        \n",
    "\n",
    "\"\"\"\n",
    "    Dataframe preprocess helper function\n",
    "    input:\n",
    "        df (dataframe): input dataframe\n",
    "        col (string): column name that contains the original service types\n",
    "    output:\n",
    "        df_pp (dataframe): processed dataframe\n",
    "\"\"\"\n",
    "#Dataframe pre-processing\n",
    "def preprocess(df,col):\n",
    "    df_pp=df.copy()\n",
    "    df_pp=df_pp.dropna()    #dropping any rows with NaN values\n",
    "    df_pp[col]=df_pp[col].str.lower()    #lower all case in OrigService\n",
    "    df_pp[col]=df_pp[col].str.replace('[^A-Za-z\\s]+', ' ')    #remove all special characters\n",
    "    df_pp[col]=df_pp[col].str.replace('services','')    #remove word: \"services\" from string\n",
    "    df_pp[col]=df_pp[col].str.replace('service','')    #remove word: \"service\" from string\n",
    "    df_pp[col]=df_pp[col].str.replace('fees','')    #remove word: \"fees\" from string\n",
    "    df_pp=df_pp.reset_index()\n",
    "    return df_pp\n",
    "\n",
    "\"\"\"\n",
    "    Spell check function\n",
    "    input:\n",
    "        df (dataframe): input dataframe\n",
    "        col (string): column name that contains the original service types\n",
    "    output:\n",
    "        df_ac (dataframe): spell checked dataframe\n",
    "\"\"\"\n",
    "#Call spell check if necessary\n",
    "def spellcheck(df,col):\n",
    "    df_ac=df.copy()\n",
    "    temp = df_ac[col].tolist()\n",
    "    for i in range(len(temp)):\n",
    "        temp[i] = spell(temp[i])\n",
    "    df_ac[col] = temp\n",
    "    return df_ac\n",
    "\n",
    "\"\"\"\n",
    "    Spell check function\n",
    "    input:\n",
    "        df (dataframe): input dataframe\n",
    "        orig (string): column name that contains the original service types\n",
    "        final (string): column name that contains the labeled service types\n",
    "        tsize (float): test to train ratio\n",
    "        rstate (integer): random state number\n",
    "    output:\n",
    "        all_labels (list): predicted labels\n",
    "        Accuracy (float): accuracy of the model\n",
    "        X_test.index (list): index of the predicted labels\n",
    "\"\"\"\n",
    "#Classifier pipeline\n",
    "def model(df, orig, final, tsize, rstate):\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    classifier = Pipeline([\n",
    "        ('vectorizer', CountVectorizer()),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', OneVsRestClassifier(linear_model.LogisticRegression(class_weight='balanced')))])\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(df[orig], df[final], test_size=tsize, random_state=rstate)\n",
    "    for i in Y_train.index:\n",
    "        Y_train[i]=[Y_train[i]]\n",
    "    Y_train = mlb.fit_transform(Y_train)\n",
    "    classifier.fit(X_train, Y_train)\n",
    "    predicted = classifier.predict(X_test)\n",
    "    all_labels = mlb.inverse_transform(predicted)\n",
    "    for i in range(0,len(all_labels)):\n",
    "        all_labels[i]=' '.join(all_labels[i])\n",
    "    c = (np.array(Y_test.reset_index()[final]) == np.array(all_labels))\n",
    "    Accuracy = sum(c)/len(Y_test)*100\n",
    "    print('Accuracy = ' + str(round(Accuracy, 2)) + '%')  #>80% will be fine as the model is evaluated with another metric\n",
    "    return all_labels, Accuracy, X_test.index\n",
    "\n",
    "\"\"\"\n",
    "    Helper function that writes output to csv\n",
    "    input:\n",
    "        df (dataframe): output data frame\n",
    "        ind (list): index of the predicted labels\n",
    "        pred (list): predicted labels\n",
    "\"\"\"\n",
    "#output function\n",
    "def output_df(df, ind, pred):\n",
    "    df['Predictions']=''\n",
    "    df['Predictions'][ind]=pred\n",
    "    df = df.drop(['index'], axis = 1)\n",
    "    df.to_csv('vc_output.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VC Variables declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variable declaration:\n",
    "inputfile = 'vc_input.csv'\n",
    "outputfile = 'vc_output.csv'\n",
    "orig = 'OrigService'\n",
    "final = 'FinalService'\n",
    "tsize = 0.5\n",
    "rstate = 24\n",
    "scheck = 'off'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VC Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Main function\"\"\"\n",
    "\n",
    "#Main function\n",
    "df = read_txt(inputfile)\n",
    "df = preprocess(df,orig)\n",
    "pred, acc, ind = model(df, orig, final, tsize, rstate)\n",
    "output_df(df, ind, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosine Similarity for Company Names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CS functions and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This is the algorithm that group companies by the most commonly mentioned\n",
    "name using cosine similarity\"\"\"\n",
    "\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import operator\n",
    "import re, math\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\"\"\"\n",
    "    Function for reading input file\n",
    "    input:\n",
    "        filename (string): name of the file\n",
    "    output:\n",
    "        df (dataframe): input dataframe\n",
    "\"\"\"\n",
    "#read input file\n",
    "def read_txt(filename):\n",
    "    if filename.split('.')[1] == 'csv':\n",
    "        df = pd.read_csv(r'vc_input_train.csv')\n",
    "        return df\n",
    "    elif filename.split('.')[1] == 'txt':\n",
    "        with open(\"vc_input_train.txt\", encoding='utf-16') as f:\n",
    "            contents = f.read()\n",
    "        if sys.version_info[0] < 3: \n",
    "            from StringIO import StringIO\n",
    "        else:\n",
    "            from io import StringIO\n",
    "        TESTDATA=StringIO(contents)\n",
    "        df = pd.read_csv(TESTDATA, sep=\"|\", error_bad_lines=False)\n",
    "        return df\n",
    "    else:\n",
    "        print(\"file type non recognized\")\n",
    "        \n",
    "\"\"\"\n",
    "    Helper function for removing null entries\n",
    "    input:\n",
    "        df (dataframe): dataframe containing the company names\n",
    "        final_serv (string): column name from input that lists the service categories\n",
    "    output:\n",
    "        df_nona (dataframe): dataframe with no null entries\n",
    "\"\"\"\n",
    "#Remove null entries\n",
    "def remove_null(df, final_serv):\n",
    "    df_nona = df[df[final_serv].isnull()==0]\n",
    "    return df_nona\n",
    "\n",
    "\"\"\"\n",
    "    Helper function for grouping company names according to their service categories\n",
    "    input:\n",
    "        df (dataframe): dataframe containing the company names\n",
    "        g (integer): iteration number\n",
    "        col (string): column name that contains the original company names\n",
    "    output:\n",
    "        df_type (dataframe): dataframe for each service category\n",
    "\"\"\"\n",
    "#Seperate the companies according to their service categories\n",
    "def create_df_for_each_service_type(dfg, g, col):\n",
    "    df_type = dfg.get_group(gp_names[g]).sort_values(col).reset_index()\n",
    "    df_type[col] = df_type[col].str.upper()\n",
    "    df_type['Grouped Names'] = df_type[col]\n",
    "    return df_type\n",
    "\n",
    "\"\"\"\n",
    "    Helper function for creating a list of company names from the input dataframe\n",
    "    input:\n",
    "        df (dataframe): dataframe containing the company names\n",
    "        col (string): column name that contains the original company names\n",
    "    output:\n",
    "        companylist (list): list containing company names in each category\n",
    "\"\"\"\n",
    "#Creat list that contains company names\n",
    "def create_company_vectors(df, col):\n",
    "    templist = np.asarray(df[col])\n",
    "    companylist=[]\n",
    "    for w1 in templist:\n",
    "        companylist = companylist + [text_to_vector(w1)]\n",
    "    return companylist\n",
    "\n",
    "\"\"\"\n",
    "    Function that compare company names with consine similiarity and replace names with most commonly mentioned name\n",
    "    input:\n",
    "        df (dataframe): dataframe containing the company names\n",
    "        col (string): column name that contains the original company names\n",
    "        cos_similarity (matrix): cosine similiarity matrix\n",
    "        cos_damp (float): cosine similarity damping coefficient\n",
    "    output:\n",
    "        df (dataframe): dataframe with companies name replaced\n",
    "\"\"\"\n",
    "#Compare names with cosine similiarity\n",
    "def compare_company_names(df, col, cos_similarity, cos_damp):\n",
    "    companylist=np.asarray(df[col])\n",
    "    skip=[]\n",
    "    for j in range(len(companylist)):\n",
    "        if j not in skip:\n",
    "            templist=[]\n",
    "            tempid=[]\n",
    "            for i in range(0,len(companylist)):\n",
    "                if (cos_similarity[j]<-cos_damp).tolist()[i] == True:\n",
    "                    templist = templist + [companylist[i]]\n",
    "                    tempid = tempid + [i]\n",
    "            if len(templist)>1:\n",
    "                listf=[]\n",
    "                idf=[]\n",
    "                for k in range(0,len(templist)):\n",
    "                    if companylist[j][0] == templist[k][0]:\n",
    "                        listf = listf + [templist[k]]\n",
    "                        idf = idf + [tempid[k]]\n",
    "                for m in idf:\n",
    "                    df['Grouped Names'][m]=max(listf, key=listf.count)\n",
    "            skip = skip + tempid\n",
    "    return df\n",
    "\n",
    "\"\"\"\n",
    "    Helper function that calculates cosine angle\n",
    "    input:\n",
    "        vec1 (vector): vector 1\n",
    "        vec2 (vector): vector 2\n",
    "    output:\n",
    "        cosine angle\n",
    "\"\"\"\n",
    "#Helper function to calculate cosine angle\n",
    "def get_cosine(vec1, vec2):\n",
    "    intersection = set(vec1.keys()) & set(vec2.keys())\n",
    "    numerator = sum([vec1[x] * vec2[x] for x in intersection])\n",
    "    sum1 = sum([vec1[x]**2 for x in vec1.keys()])\n",
    "    sum2 = sum([vec2[x]**2 for x in vec2.keys()])\n",
    "    denominator = math.sqrt(sum1) * math.sqrt(sum2)\n",
    "    if not denominator:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return float(numerator) / denominator\n",
    "    \n",
    "\"\"\"\n",
    "    Helper function that transform text to vector\n",
    "    input:\n",
    "        text (string): text string\n",
    "    output:\n",
    "        word vector\n",
    "\"\"\"\n",
    "#Helper function to transform text to vector\n",
    "def text_to_vector(text):\n",
    "    words = re.compile(r'\\w+').findall(text)\n",
    "    return Counter(words)\n",
    "\n",
    "\"\"\"\n",
    "    Helper function that writes output to csv\n",
    "    input:\n",
    "        df_print (dataframe): output data frame\n",
    "        gp_names (string): output service category\n",
    "        i (integer): iteration number\n",
    "\"\"\"\n",
    "#Printing output to csv file\n",
    "def print_output(df_print, gp_names, i):\n",
    "    filename = gp_names[i].replace('/', '_') + '.csv'\n",
    "    df_print.to_csv(filename, sep=',', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CS Variable Declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variable Declaration\n",
    "inputfile  = 'cs_input.csv'       #Name of input file\n",
    "final_serv = 'FinalService'       #Column name for final service type of each company\n",
    "orig_name  = 'origName'           #Column name consisting original company names\n",
    "cos_damp   = 0.5                  #Cosine similarity threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CS Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Main function\"\"\"\n",
    "\n",
    "#Read input\n",
    "df = read_txt(inputfile)\n",
    "#Remove null entries\n",
    "df_nona = remove_null(df, final_serv)\n",
    "#Create groupby object by grouping by service types\n",
    "dfg = df_nona.groupby(final_serv)\n",
    "gp_names = list(dfg.groups.keys())\n",
    "\n",
    "#For loop to compare company names for each service type\n",
    "for g in range(len(gp_names)):\n",
    "    #Create a dataframe with data from each service type\n",
    "    df_type = create_df_for_each_service_type(dfg, g, orig_name)\n",
    "    #Create company name vectors for each entry in the dataframe\n",
    "    company_vec = create_company_vectors(df_type, orig_name)\n",
    "    #Calculate cosine similiarity matrix\n",
    "    cos_similarity = -1*np.array([[get_cosine(w1,w2) for w1 in company_vec] for w2 in company_vec])\n",
    "    #Compare company names using cosine similiarity matrix and return unified names for each company to dataframe\n",
    "    df_print = compare_company_names(df_type, orig_name, cos_similarity, cos_damp)\n",
    "    #Print dataframe containing unified company names to csv for each service type\n",
    "    print_output(df_print, gp_names, g)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
